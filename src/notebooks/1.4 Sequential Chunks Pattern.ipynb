{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1.4: Sequential Chunks Pattern\n",
    "\n",
    "Este notebook prueba el patrÃ³n **SEQUENTIAL_CHUNKS** con datos reales.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. **Limpiar el grafo** antes de empezar\n",
    "2. **Crear patrÃ³n SEQUENTIAL_CHUNKS** con relaciones NEXT_CHUNK\n",
    "3. **Ingerir 3 documentos** usando el patrÃ³n secuencial\n",
    "4. **Explorar el grafo** creado\n",
    "5. **Probar bÃºsquedas** con los patrones GraphRAG implementados\n",
    "\n",
    "## PatrÃ³n SEQUENTIAL_CHUNKS\n",
    "\n",
    "- **Chunk**: Fragmentos de texto\n",
    "- **NEXT_CHUNK**: RelaciÃ³n entre chunks consecutivos\n",
    "\n",
    "**Estructura:**\n",
    "```\n",
    "Chunk -[:NEXT_CHUNK]-> Chunk\n",
    "```\n",
    "\n",
    "Este patrÃ³n mantiene el orden secuencial de los chunks sin estructura jerÃ¡rquica adicional."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def add_src_to_path(path_folder: str):\n",
    "    ''' \n",
    "    Helper function for adding the \"path_folder\" directory to the path.\n",
    "    in order to work on notebooks and scripts\n",
    "    '''\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    base_path = Path().resolve()\n",
    "    for parent in [base_path] + list(base_path.parents):\n",
    "        candidate = parent / path_folder\n",
    "        if candidate.exists():\n",
    "            parent_dir = candidate.parent\n",
    "            if str(parent_dir) not in sys.path:\n",
    "                sys.path.insert(0, str(parent_dir))\n",
    "                print(f\"Path Folder parent added: {parent_dir}\")\n",
    "            if str(candidate) not in sys.path:\n",
    "                sys.path.append(str(candidate))\n",
    "                print(f\"Path Folder {path_folder} added: {candidate}\")\n",
    "            return\n",
    "    print(f\"Not found '{path_folder}' folder on the hierarchy of directories\")\n",
    "\n",
    "# Agregar carpetas necesarias al path\n",
    "add_src_to_path(path_folder=\"src\")\n",
    "add_src_to_path(path_folder=\"src/utils\")\n",
    "add_src_to_path(path_folder=\"src/data\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importar librerÃ­as necesarias\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Importar handlers\n",
    "from src.utils.handlers import find_in_project\n",
    "\n",
    "# Importar ungraph\n",
    "try:\n",
    "    import ungraph\n",
    "    print(\"âœ… Ungraph importado como paquete instalado\")\n",
    "except ImportError:\n",
    "    import src\n",
    "    ungraph = src\n",
    "    print(\"âœ… Ungraph importado desde src/ (modo desarrollo)\")\n",
    "\n",
    "# Importar servicios para limpieza\n",
    "from infrastructure.services.neo4j_index_service import Neo4jIndexService\n",
    "\n",
    "# Importar patrones\n",
    "from domain.value_objects.graph_pattern import GraphPattern, NodeDefinition, RelationshipDefinition\n",
    "\n",
    "print(f\"ðŸ“¦ Ungraph version: {ungraph.__version__}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: ConfiguraciÃ³n y Limpieza\n",
    "\n",
    "Configuramos Neo4j y limpiamos el grafo antes de empezar."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configurar Neo4j\n",
    "ungraph.configure(\n",
    "    neo4j_uri=\"bolt://localhost:7687\",\n",
    "    neo4j_user=\"neo4j\",\n",
    "    neo4j_password=\"Ungraph22\",  # âš ï¸ CAMBIAR: Usa tu contraseÃ±a real\n",
    "    neo4j_database=\"neo4j\",\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"âœ… ConfiguraciÃ³n completada\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Limpiar el grafo antes de empezar\n",
    "print(\"ðŸ§¹ Limpiando grafo...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "index_service = Neo4jIndexService()\n",
    "\n",
    "# Limpiar todos los nodos y relaciones\n",
    "try:\n",
    "    index_service.clean_graph()\n",
    "    print(\"âœ… Grafo limpiado (todos los nodos y relaciones eliminados)\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error al limpiar grafo: {e}\")\n",
    "\n",
    "# Eliminar todos los Ã­ndices\n",
    "try:\n",
    "    index_service.drop_all_indexes()\n",
    "    print(\"âœ… Ãndices eliminados\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error al eliminar Ã­ndices: {e}\")\n",
    "\n",
    "print(\"\\nâœ… Limpieza completada. Listo para ingesta.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Preparar Documentos\n",
    "\n",
    "Localizamos los 3 documentos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Encontrar carpeta de datos\n",
    "data_path = find_in_project(\n",
    "    target=\"data\",\n",
    "    search_type=\"folder\",\n",
    "    project_root=None\n",
    ")\n",
    "\n",
    "if data_path:\n",
    "    print(f\"âœ… Carpeta de datos encontrada: {data_path}\")\n",
    "    \n",
    "    # Seleccionar los 3 documentos de prueba\n",
    "    test_files = [\n",
    "        data_path / \"110225.md\",\n",
    "        data_path / \"AnnyLetter.txt\",\n",
    "        data_path / \"Usar sÃ­mboles de silencio de corchea.docx\"\n",
    "    ]\n",
    "    \n",
    "    # Verificar que existen\n",
    "    available_files = [f for f in test_files if f.exists()]\n",
    "    print(f\"\\nðŸ“„ Archivos disponibles ({len(available_files)}/{len(test_files)}):\")\n",
    "    for f in available_files:\n",
    "        print(f\"   âœ… {f.name}\")\n",
    "    \n",
    "    for f in test_files:\n",
    "        if not f.exists():\n",
    "            print(f\"   âš ï¸  No encontrado: {f.name}\")\n",
    "else:\n",
    "    print(\"âŒ Carpeta de datos no encontrada\")\n",
    "    available_files = []"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Crear PatrÃ³n SEQUENTIAL_CHUNKS\n",
    "\n",
    "Definimos el patrÃ³n secuencial con chunks y relaciones NEXT_CHUNK."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Crear patrÃ³n SEQUENTIAL_CHUNKS\n",
    "print(\"ðŸ“ CREANDO PATRÃ“N SEQUENTIAL_CHUNKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Nodo Chunk\n",
    "chunk_node = NodeDefinition(\n",
    "    label=\"Chunk\",\n",
    "    required_properties={\n",
    "        \"chunk_id\": str,\n",
    "        \"content\": str,\n",
    "        \"embeddings\": list,\n",
    "        \"embeddings_dimensions\": int\n",
    "    },\n",
    "    optional_properties={\n",
    "        \"chunk_id_consecutive\": int,\n",
    "        \"source_file\": str\n",
    "    },\n",
    "    indexes=[\"chunk_id\", \"chunk_id_consecutive\"]\n",
    ")\n",
    "\n",
    "# RelaciÃ³n: Chunk siguiente\n",
    "next_chunk_rel = RelationshipDefinition(\n",
    "    from_node=\"Chunk\",\n",
    "    to_node=\"Chunk\",\n",
    "    relationship_type=\"NEXT_CHUNK\",\n",
    "    direction=\"OUTGOING\"\n",
    ")\n",
    "\n",
    "SEQUENTIAL_CHUNKS_PATTERN = GraphPattern(\n",
    "    name=\"SEQUENTIAL_CHUNKS\",\n",
    "    description=\"Chunks con relaciones NEXT_CHUNK entre consecutivos. Ãštil para mantener orden secuencial.\",\n",
    "    node_definitions=[chunk_node],\n",
    "    relationship_definitions=[next_chunk_rel],\n",
    "    search_patterns=[\"basic\", \"hybrid\"]\n",
    ")\n",
    "\n",
    "print(f\"âœ… PatrÃ³n creado: {SEQUENTIAL_CHUNKS_PATTERN.name}\")\n",
    "print(f\"   Nodos: {[n.label for n in SEQUENTIAL_CHUNKS_PATTERN.node_definitions]}\")\n",
    "print(f\"   Relaciones: {[r.relationship_type for r in SEQUENTIAL_CHUNKS_PATTERN.relationship_definitions]}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Ingesta con PatrÃ³n SEQUENTIAL_CHUNKS\n",
    "\n",
    "Ingerimos los documentos usando el patrÃ³n secuencial."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ingesta con patrÃ³n SEQUENTIAL_CHUNKS\n",
    "print(\"ðŸ“¥ INGESTA CON PATRÃ“N SEQUENTIAL_CHUNKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_chunks_sequential = []\n",
    "\n",
    "for file_path in available_files:\n",
    "    print(f\"\\nðŸ“„ Procesando: {file_path.name}\")\n",
    "    try:\n",
    "        chunks = ungraph.ingest_document(\n",
    "            file_path,\n",
    "            pattern=SEQUENTIAL_CHUNKS_PATTERN,\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            clean_text=True\n",
    "        )\n",
    "        all_chunks_sequential.extend(chunks)\n",
    "        print(f\"   âœ… {len(chunks)} chunks creados\")\n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… Total chunks con patrÃ³n SEQUENTIAL_CHUNKS: {len(all_chunks_sequential)}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Explorar Grafo\n",
    "\n",
    "Exploramos la estructura del grafo creado."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Explorar estructura del grafo\n",
    "from src.utils.graph_operations import graph_session\n",
    "\n",
    "driver = graph_session()\n",
    "with driver.session() as session:\n",
    "    # Contar nodos por tipo\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n)[0] as label, count(n) as count\n",
    "        ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"ðŸ“Š ESTRUCTURA DEL GRAFO:\")\n",
    "    print(\"=\" * 80)\n",
    "    for record in result:\n",
    "        print(f\"   {record['label']}: {record['count']} nodos\")\n",
    "    \n",
    "    # Contar relaciones\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN type(r) as rel_type, count(r) as count\n",
    "        ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nðŸ”— RELACIONES:\")\n",
    "    for record in result:\n",
    "        print(f\"   {record['rel_type']}: {record['count']} relaciones\")\n",
    "\n",
    "driver.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4.1: Visualizar Grafo\n",
    "\n",
    "Visualizamos el grafo usando yFiles for Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Importar funciones de visualizaciÃ³n\n",
    "from src.notebooks.graph_visualization import (\n",
    "    visualize_file_page_chunk_pattern,\n",
    "    visualize_simple_chunk_pattern,\n",
    "    visualize_lexical_graph_pattern,\n",
    "    visualize_hierarchical_pattern,\n",
    "    visualize_sequential_chunks_pattern,\n",
    "    visualize_pattern_structure,\n",
    "    visualize_custom_query\n",
    ")\n",
    "\n",
    "print(\"âœ… Funciones de visualizaciÃ³n importadas\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5: Probar BÃºsquedas\n",
    "\n",
    "Probamos los patrones de bÃºsqueda GraphRAG implementados."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Probar bÃºsquedas\n",
    "test_query = \"test\"\n",
    "print(f\"ðŸ” PROBANDO BÃšSQUEDAS CON QUERY: '{test_query}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Basic Retriever\n",
    "print(\"\\n1. Basic Retriever:\")\n",
    "try:\n",
    "    results = ungraph.search_with_pattern(\n",
    "        test_query,\n",
    "        pattern_type=\"basic\",\n",
    "        limit=3\n",
    "    )\n",
    "    print(f\"   âœ… {len(results)} resultados\")\n",
    "    if results:\n",
    "        print(f\"   Score promedio: {sum(r.score for r in results) / len(results):.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error: {e}\")\n",
    "\n",
    "# 2. Metadata Filtering\n",
    "print(\"\\n2. Metadata Filtering:\")\n",
    "try:\n",
    "    # Obtener un filename del grafo\n",
    "    driver = graph_session()\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (f:File) RETURN f.filename as filename LIMIT 1\")\n",
    "        record = result.single()\n",
    "        if not record:\n",
    "            # Intentar con Chunk si no hay File\n",
    "            result = session.run(\"MATCH (c:Chunk) RETURN c.source_file as filename LIMIT 1\")\n",
    "            record = result.single()\n",
    "        if record:\n",
    "            filename = record[\"filename\"]\n",
    "            results = ungraph.search_with_pattern(\n",
    "                test_query,\n",
    "                pattern_type=\"metadata_filtering\",\n",
    "                metadata_filters={\"filename\": filename},\n",
    "                limit=3\n",
    "            )\n",
    "            print(f\"   âœ… {len(results)} resultados (filtrado por '{filename}')\")\n",
    "        else:\n",
    "            print(\"   âš ï¸  No hay archivos en el grafo\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   âŒ Error: {e}\")\n",
    "\n",
    "# 3. Parent-Child Retriever (si aplica)\n",
    "print(\"\\n3. Parent-Child Retriever:\")\n",
    "try:\n",
    "    results = ungraph.search_with_pattern(\n",
    "        test_query,\n",
    "        pattern_type=\"parent_child\",\n",
    "        parent_label=\"Page\",\n",
    "        child_label=\"Chunk\",\n",
    "        relationship_type=\"HAS_CHUNK\",\n",
    "        limit=3\n",
    "    )\n",
    "    print(f\"   âœ… {len(results)} resultados\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸  No aplica para este patrÃ³n: {e}\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualizar patrÃ³n SEQUENTIAL_CHUNKS\n",
    "print(\"ðŸŽ¨ VISUALIZANDO PATRÃ“N SEQUENTIAL_CHUNKS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "driver = graph_session()\n",
    "try:\n",
    "    visualize_sequential_chunks_pattern(driver, limit=25)\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Error al visualizar: {e}\")\n",
    "    print(\"ðŸ’¡ AsegÃºrate de tener yfiles_jupyter_graphs_for_neo4j instalado\")\n",
    "finally:\n",
    "    driver.close()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6: Resumen\n",
    "\n",
    "Resumen del patrÃ³n SEQUENTIAL_CHUNKS."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\"ðŸ“Š RESUMEN DEL PATRÃ“N SEQUENTIAL_CHUNKS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Chunks creados: {len(all_chunks_sequential)}\")\n",
    "print(f\"Estructura: Chunk -[:NEXT_CHUNK]-> Chunk\")\n",
    "print(f\"Uso recomendado: Mantener orden secuencial sin estructura jerÃ¡rquica\")\n",
    "print(\"\\nâœ… Notebook completado exitosamente\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}