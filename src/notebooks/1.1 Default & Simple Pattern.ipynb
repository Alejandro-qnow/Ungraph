{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1.1: Default & Simple Pattern\n",
    "\n",
    "Este notebook prueba el patr√≥n **FILE_PAGE_CHUNK** (default) y el patr√≥n **SIMPLE_CHUNK** con datos reales.\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "1. **Limpiar el grafo** antes de empezar\n",
    "2. **Ingerir 3 documentos** usando cada patr√≥n\n",
    "3. **Explorar el grafo** creado\n",
    "4. **Probar b√∫squedas** con los patrones GraphRAG implementados\n",
    "\n",
    "## Patrones a Probar\n",
    "\n",
    "- ‚úÖ **FILE_PAGE_CHUNK**: Patr√≥n default con estructura File ‚Üí Page ‚Üí Chunk\n",
    "- ‚úÖ **SIMPLE_CHUNK**: Solo chunks sin estructura jer√°rquica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_src_to_path(path_folder: str):\n",
    "    ''' \n",
    "    Helper function for adding the \"path_folder\" directory to the path.\n",
    "    in order to work on notebooks and scripts\n",
    "    '''\n",
    "    import sys\n",
    "    from pathlib import Path\n",
    "\n",
    "    base_path = Path().resolve()\n",
    "    for parent in [base_path] + list(base_path.parents):\n",
    "        candidate = parent / path_folder\n",
    "        if candidate.exists():\n",
    "            parent_dir = candidate.parent\n",
    "            if str(parent_dir) not in sys.path:\n",
    "                sys.path.insert(0, str(parent_dir))\n",
    "                print(f\"Path Folder parent added: {parent_dir}\")\n",
    "            if str(candidate) not in sys.path:\n",
    "                sys.path.append(str(candidate))\n",
    "                print(f\"Path Folder {path_folder} added: {candidate}\")\n",
    "            return\n",
    "    print(f\"Not found '{path_folder}' folder on the hierarchy of directories\")\n",
    "\n",
    "# Agregar carpetas necesarias al path\n",
    "add_src_to_path(path_folder=\"src\")\n",
    "add_src_to_path(path_folder=\"src/utils\")\n",
    "add_src_to_path(path_folder=\"src/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ungraph importado desde src/ (modo desarrollo)\n",
      "üì¶ Ungraph version: 0.1.0\n"
     ]
    }
   ],
   "source": [
    "# Importar librer√≠as necesarias\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# Importar handlers\n",
    "from src.utils.handlers import find_in_project\n",
    "\n",
    "# Importar ungraph\n",
    "try:\n",
    "    import ungraph\n",
    "    print(\"‚úÖ Ungraph importado como paquete instalado\")\n",
    "except ImportError:\n",
    "    import src\n",
    "    ungraph = src\n",
    "    print(\"‚úÖ Ungraph importado desde src/ (modo desarrollo)\")\n",
    "\n",
    "# Importar servicios para limpieza\n",
    "from infrastructure.services.neo4j_index_service import Neo4jIndexService\n",
    "\n",
    "# Importar patrones\n",
    "from domain.value_objects.predefined_patterns import FILE_PAGE_CHUNK_PATTERN\n",
    "from domain.value_objects.graph_pattern import GraphPattern, NodeDefinition\n",
    "\n",
    "print(f\"üì¶ Ungraph version: {ungraph.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Configuraci√≥n y Limpieza\n",
    "\n",
    "Configuramos Neo4j y limpiamos el grafo antes de empezar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n completada\n"
     ]
    }
   ],
   "source": [
    "# Configurar Neo4j\n",
    "ungraph.configure(\n",
    "    neo4j_uri=\"bolt://localhost:7687\",\n",
    "    neo4j_user=\"neo4j\",\n",
    "    neo4j_password=\"Ungraph22\",  # ‚ö†Ô∏è CAMBIAR: Usa tu contrase√±a real\n",
    "    neo4j_database=\"neo4j\",\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Limpiando grafo...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error cleaning graph: The result is out of scope. The associated transaction has been closed. Results can only be used while the transaction is open.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Error al limpiar grafo: The result is out of scope. The associated transaction has been closed. Results can only be used while the transaction is open.\n",
      "‚úÖ √çndices eliminados\n",
      "\n",
      "‚úÖ Limpieza completada. Listo para ingesta.\n"
     ]
    }
   ],
   "source": [
    "# Limpiar el grafo antes de empezar\n",
    "print(\"üßπ Limpiando grafo...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "index_service = Neo4jIndexService()\n",
    "\n",
    "# Limpiar todos los nodos y relaciones\n",
    "try:\n",
    "    index_service.clean_graph()\n",
    "    print(\"‚úÖ Grafo limpiado (todos los nodos y relaciones eliminados)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error al limpiar grafo: {e}\")\n",
    "\n",
    "# Eliminar todos los √≠ndices\n",
    "try:\n",
    "    index_service.drop_all_indexes()\n",
    "    print(\"‚úÖ √çndices eliminados\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error al eliminar √≠ndices: {e}\")\n",
    "\n",
    "print(\"\\n‚úÖ Limpieza completada. Listo para ingesta.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Preparar Documentos\n",
    "\n",
    "Localizamos los 3 documentos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Carpeta de datos encontrada: D:\\projects\\Ungraph\\src\\data\n",
      "\n",
      "üìÑ Archivos disponibles (3/3):\n",
      "   ‚úÖ 110225.md\n",
      "   ‚úÖ AnnyLetter.txt\n",
      "   ‚úÖ Usar s√≠mboles de silencio de corchea.docx\n"
     ]
    }
   ],
   "source": [
    "# Encontrar carpeta de datos\n",
    "data_path = find_in_project(\n",
    "    target=\"data\",\n",
    "    search_type=\"folder\",\n",
    "    project_root=None\n",
    ")\n",
    "\n",
    "if data_path:\n",
    "    print(f\"‚úÖ Carpeta de datos encontrada: {data_path}\")\n",
    "    \n",
    "    # Seleccionar los 3 documentos de prueba\n",
    "    test_files = [\n",
    "        data_path / \"110225.md\",\n",
    "        data_path / \"AnnyLetter.txt\",\n",
    "        data_path / \"Usar s√≠mboles de silencio de corchea.docx\"\n",
    "    ]\n",
    "    \n",
    "    # Verificar que existen\n",
    "    available_files = [f for f in test_files if f.exists()]\n",
    "    print(f\"\\nüìÑ Archivos disponibles ({len(available_files)}/{len(test_files)}):\")\n",
    "    for f in available_files:\n",
    "        print(f\"   ‚úÖ {f.name}\")\n",
    "    \n",
    "    for f in test_files:\n",
    "        if not f.exists():\n",
    "            print(f\"   ‚ö†Ô∏è  No encontrado: {f.name}\")\n",
    "else:\n",
    "    print(\"‚ùå Carpeta de datos no encontrada\")\n",
    "    available_files = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Ingesta con Patr√≥n FILE_PAGE_CHUNK (Default)\n",
    "\n",
    "Ingerimos los documentos usando el patr√≥n default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• INGESTA CON PATR√ìN FILE_PAGE_CHUNK (DEFAULT)\n",
      "================================================================================\n",
      "\n",
      "üìÑ Procesando: 110225.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.index.vector.createNodeIndex' has been replaced by 'CREATE VECTOR INDEX')} {position: line: 2, column: 9, offset: 9} for query: \"\\n        CALL db.index.vector.createNodeIndex(\\n            'chunk_embeddings',\\n            'Chunk',\\n            'embeddings',\\n            384,\\n            'cosine'\\n        )\\n        \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk relationships created successfully\n",
      "   ‚úÖ 9 chunks creados\n",
      "\n",
      "üìÑ Procesando: AnnyLetter.txt\n",
      "Chunk relationships created successfully\n",
      "   ‚úÖ 23 chunks creados\n",
      "\n",
      "üìÑ Procesando: Usar s√≠mboles de silencio de corchea.docx\n",
      "Chunk relationships created successfully\n",
      "   ‚úÖ 27 chunks creados\n",
      "\n",
      "‚úÖ Total chunks con patr√≥n FILE_PAGE_CHUNK: 59\n"
     ]
    }
   ],
   "source": [
    "# Ingesta con patr√≥n FILE_PAGE_CHUNK (default)\n",
    "print(\"üì• INGESTA CON PATR√ìN FILE_PAGE_CHUNK (DEFAULT)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_chunks_default = []\n",
    "\n",
    "for file_path in available_files:\n",
    "    print(f\"\\nüìÑ Procesando: {file_path.name}\")\n",
    "    try:\n",
    "        chunks = ungraph.ingest_document(\n",
    "            file_path,\n",
    "            pattern=FILE_PAGE_CHUNK_PATTERN,  # Patr√≥n default\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            clean_text=True\n",
    "        )\n",
    "        all_chunks_default.extend(chunks)\n",
    "        print(f\"   ‚úÖ {len(chunks)} chunks creados\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total chunks con patr√≥n FILE_PAGE_CHUNK: {len(all_chunks_default)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Explorar Grafo FILE_PAGE_CHUNK\n",
    "\n",
    "Exploramos la estructura del grafo creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä ESTRUCTURA DEL GRAFO (FILE_PAGE_CHUNK):\n",
      "================================================================================\n",
      "   Chunk: 59 nodos\n",
      "   File: 3 nodos\n",
      "   Page: 3 nodos\n",
      "\n",
      "üîó RELACIONES:\n",
      "   NEXT_CHUNK: 135 relaciones\n",
      "   HAS_CHUNK: 59 relaciones\n",
      "   CONTAINS: 3 relaciones\n"
     ]
    }
   ],
   "source": [
    "# Explorar estructura del grafo\n",
    "from src.utils.graph_operations import graph_session\n",
    "\n",
    "driver = graph_session()\n",
    "with driver.session() as session:\n",
    "    # Contar nodos por tipo\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n)[0] as label, count(n) as count\n",
    "        ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"üìä ESTRUCTURA DEL GRAFO (FILE_PAGE_CHUNK):\")\n",
    "    print(\"=\" * 80)\n",
    "    for record in result:\n",
    "        print(f\"   {record['label']}: {record['count']} nodos\")\n",
    "    \n",
    "    # Contar relaciones\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH ()-[r]->()\n",
    "        RETURN type(r) as rel_type, count(r) as count\n",
    "        ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"\\nüîó RELACIONES:\")\n",
    "    for record in result:\n",
    "        print(f\"   {record['rel_type']}: {record['count']} relaciones\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4.1: Visualizar Grafo FILE_PAGE_CHUNK\n",
    "\n",
    "Visualizamos el grafo usando yFiles for Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® VISUALIZANDO PATR√ìN FILE_PAGE_CHUNK\n",
      "================================================================================\n",
      "Visualizando estructura de: Usar s√≠mboles de silencio de corchea.docx\n",
      "‚ö†Ô∏è  Error al visualizar: Neo4jGraphWidget.__init__() got an unexpected keyword argument 'parameters'\n",
      "üí° Aseg√∫rate de tener yfiles_jupyter_graphs_for_neo4j instalado\n",
      "   Instalar con: pip install yfiles-jupyter-graphs-for-neo4j\n"
     ]
    }
   ],
   "source": [
    "# Importar funciones de visualizaci√≥n\n",
    "from src.notebooks.graph_visualization import visualize_file_page_chunk_pattern\n",
    "from src.utils.graph_operations import graph_session\n",
    "\n",
    "print(\"üé® VISUALIZANDO PATR√ìN FILE_PAGE_CHUNK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "driver = graph_session()\n",
    "try:\n",
    "    # Obtener el primer filename disponible\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (f:File) RETURN f.filename as filename LIMIT 1\")\n",
    "        record = result.single()\n",
    "        if record:\n",
    "            filename = record[\"filename\"]\n",
    "            print(f\"Visualizando estructura de: {filename}\")\n",
    "            visualize_file_page_chunk_pattern(driver, limit=15, filename=filename)\n",
    "        else:\n",
    "            print(\"Visualizando estructura general (sin filtro)\")\n",
    "            visualize_file_page_chunk_pattern(driver, limit=15)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error al visualizar: {e}\")\n",
    "    print(\"üí° Aseg√∫rate de tener yfiles_jupyter_graphs_for_neo4j instalado\")\n",
    "    print(\"   Instalar con: pip install yfiles-jupyter-graphs-for-neo4j\")\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 5: Probar B√∫squedas con FILE_PAGE_CHUNK\n",
    "\n",
    "Probamos los patrones de b√∫squeda GraphRAG implementados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç PROBANDO B√öSQUEDAS CON QUERY: 'test'\n",
      "================================================================================\n",
      "\n",
      "1. Basic Retriever:\n",
      "   ‚úÖ 0 resultados\n",
      "\n",
      "2. Metadata Filtering:\n",
      "   ‚úÖ 0 resultados (filtrado por 'Usar s√≠mboles de silencio de corchea.docx')\n",
      "\n",
      "3. Parent-Child Retriever:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in search_with_pattern (parent_child): {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
      "\"        ORDER BY parent_score DESC\"\n",
      "                  ^}\n",
      "neo4j.exceptions.GqlError: {gql_status: 42N44} {gql_status_description: error: syntax error or access rule violation - inaccessible variable. It is not possible to access the variable `parent_score` declared before the RETURN clause when using `DISTINCT` or an aggregation.} {message: 42N44: It is not possible to access the variable `parent_score` declared before the RETURN clause when using `DISTINCT` or an aggregation.} {diagnostic_record: {'_classification': 'CLIENT_ERROR', '_position': {'offset': 574, 'column': 18, 'line': 16}, 'OPERATION': '', 'OPERATION_CODE': '0', 'CURRENT_SCHEMA': '/'}} {raw_classification: CLIENT_ERROR}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\projects\\Ungraph\\src\\infrastructure\\services\\neo4j_search_service.py\", line 297, in search_with_pattern\n",
      "    records = session.run(query, **params)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\session.py\", line 330, in run\n",
      "    self._auto_result._run(\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py\", line 236, in _run\n",
      "    self._attach()\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py\", line 430, in _attach\n",
      "    self._connection.fetch_message()\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py\", line 193, in inner\n",
      "    func(*args, **kwargs)\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt.py\", line 863, in fetch_message\n",
      "    res = self._process_message(tag, fields)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_bolt5.py\", line 1208, in _process_message\n",
      "    response.on_failure(summary_metadata or {})\n",
      "  File \"d:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\io\\_common.py\", line 263, in on_failure\n",
      "    raise self._hydrate_error(metadata)\n",
      "neo4j.exceptions.CypherSyntaxError: {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
      "\"        ORDER BY parent_score DESC\"\n",
      "                  ^}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ùå Error: {code: Neo.ClientError.Statement.SyntaxError} {message: In a WITH/RETURN with DISTINCT or an aggregation, it is not possible to access variables declared before the WITH/RETURN: parent_score (line 16, column 18 (offset: 574))\n",
      "\"        ORDER BY parent_score DESC\"\n",
      "                  ^}\n"
     ]
    }
   ],
   "source": [
    "# Probar b√∫squedas\n",
    "test_query = \"test\"\n",
    "print(f\"üîç PROBANDO B√öSQUEDAS CON QUERY: '{test_query}'\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. Basic Retriever\n",
    "print(\"\\n1. Basic Retriever:\")\n",
    "try:\n",
    "    results = ungraph.search_with_pattern(\n",
    "        test_query,\n",
    "        pattern_type=\"basic\",\n",
    "        limit=3\n",
    "    )\n",
    "    print(f\"   ‚úÖ {len(results)} resultados\")\n",
    "    if results:\n",
    "        print(f\"   Score promedio: {sum(r.score for r in results) / len(results):.3f}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "# 2. Metadata Filtering\n",
    "print(\"\\n2. Metadata Filtering:\")\n",
    "try:\n",
    "    # Obtener un filename del grafo\n",
    "    driver = graph_session()\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\"MATCH (f:File) RETURN f.filename as filename LIMIT 1\")\n",
    "        record = result.single()\n",
    "        if record:\n",
    "            filename = record[\"filename\"]\n",
    "            results = ungraph.search_with_pattern(\n",
    "                test_query,\n",
    "                pattern_type=\"metadata_filtering\",\n",
    "                metadata_filters={\"filename\": filename},\n",
    "                limit=3\n",
    "            )\n",
    "            print(f\"   ‚úÖ {len(results)} resultados (filtrado por '{filename}')\")\n",
    "        else:\n",
    "            print(\"   ‚ö†Ô∏è  No hay archivos en el grafo\")\n",
    "    driver.close()\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "# 3. Parent-Child Retriever\n",
    "print(\"\\n3. Parent-Child Retriever:\")\n",
    "try:\n",
    "    results = ungraph.search_with_pattern(\n",
    "        test_query,\n",
    "        pattern_type=\"parent_child\",\n",
    "        parent_label=\"Page\",\n",
    "        child_label=\"Chunk\",\n",
    "        relationship_type=\"HAS_CHUNK\",\n",
    "        limit=3\n",
    "    )\n",
    "    print(f\"   ‚úÖ {len(results)} resultados\")\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6: Limpiar y Probar Patr√≥n SIMPLE_CHUNK\n",
    "\n",
    "Ahora probamos el patr√≥n SIMPLE_CHUNK (solo chunks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù CREANDO PATR√ìN SIMPLE_CHUNK\n",
      "================================================================================\n",
      "‚úÖ Patr√≥n creado: SIMPLE_CHUNK\n",
      "   Nodos: ['Chunk']\n",
      "   Relaciones: 0\n"
     ]
    }
   ],
   "source": [
    "# Crear patr√≥n SIMPLE_CHUNK\n",
    "print(\"üìù CREANDO PATR√ìN SIMPLE_CHUNK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "simple_chunk_node = NodeDefinition(\n",
    "    label=\"Chunk\",\n",
    "    required_properties={\n",
    "        \"chunk_id\": str,\n",
    "        \"content\": str,\n",
    "        \"embeddings\": list,\n",
    "        \"embeddings_dimensions\": int\n",
    "    },\n",
    "    optional_properties={\n",
    "        \"chunk_id_consecutive\": int,\n",
    "        \"source_file\": str\n",
    "    },\n",
    "    indexes=[\"chunk_id\", \"chunk_id_consecutive\"]\n",
    ")\n",
    "\n",
    "SIMPLE_CHUNK_PATTERN = GraphPattern(\n",
    "    name=\"SIMPLE_CHUNK\",\n",
    "    description=\"Solo chunks, sin estructura File-Page. √ötil para documentos simples.\",\n",
    "    node_definitions=[simple_chunk_node],\n",
    "    relationship_definitions=[],\n",
    "    search_patterns=[\"basic\", \"hybrid\"]\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Patr√≥n creado: {SIMPLE_CHUNK_PATTERN.name}\")\n",
    "print(f\"   Nodos: {[n.label for n in SIMPLE_CHUNK_PATTERN.node_definitions]}\")\n",
    "print(f\"   Relaciones: {len(SIMPLE_CHUNK_PATTERN.relationship_definitions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error cleaning graph: The result is out of scope. The associated transaction has been closed. Results can only be used while the transaction is open.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Limpiando grafo para probar SIMPLE_CHUNK...\n"
     ]
    },
    {
     "ename": "ResultConsumedError",
     "evalue": "The result is out of scope. The associated transaction has been closed. Results can only be used while the transaction is open.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResultConsumedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Limpiar grafo antes de probar SIMPLE_CHUNK\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müßπ Limpiando grafo para probar SIMPLE_CHUNK...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mindex_service\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclean_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m index_service.drop_all_indexes()\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Grafo limpiado\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\projects\\Ungraph\\src\\infrastructure\\services\\neo4j_index_service.py:287\u001b[39m, in \u001b[36mNeo4jIndexService.clean_graph\u001b[39m\u001b[34m(self, node_labels)\u001b[39m\n\u001b[32m    285\u001b[39m             query = \u001b[33m\"\u001b[39m\u001b[33mMATCH (n) DETACH DELETE n\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    286\u001b[39m             result = session.execute_write(\u001b[38;5;28;01mlambda\u001b[39;00m tx: tx.run(query))\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m             count = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconsume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.counters.nodes_deleted\n\u001b[32m    288\u001b[39m             logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDeleted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcount\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m nodes and all relationships\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\projects\\Ungraph\\.venv\\Lib\\site-packages\\neo4j\\_sync\\work\\result.py:556\u001b[39m, in \u001b[36mResult.consume\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    508\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[33;03mConsume the remainder of this result and return the summary.\u001b[39;00m\n\u001b[32m    510\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    553\u001b[39m \u001b[33;03m    Can raise :exc:`.ResultConsumedError`.\u001b[39;00m\n\u001b[32m    554\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    555\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._out_of_scope:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResultConsumedError(\u001b[38;5;28mself\u001b[39m, _RESULT_OUT_OF_SCOPE_ERROR)\n\u001b[32m    557\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consumed:\n\u001b[32m    558\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._obtain_summary()\n",
      "\u001b[31mResultConsumedError\u001b[39m: The result is out of scope. The associated transaction has been closed. Results can only be used while the transaction is open."
     ]
    }
   ],
   "source": [
    "# Limpiar grafo antes de probar SIMPLE_CHUNK\n",
    "print(\"üßπ Limpiando grafo para probar SIMPLE_CHUNK...\")\n",
    "index_service.clean_graph()\n",
    "index_service.drop_all_indexes()\n",
    "print(\"‚úÖ Grafo limpiado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingesta con patr√≥n SIMPLE_CHUNK\n",
    "print(\"üì• INGESTA CON PATR√ìN SIMPLE_CHUNK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_chunks_simple = []\n",
    "\n",
    "for file_path in available_files:\n",
    "    print(f\"\\nüìÑ Procesando: {file_path.name}\")\n",
    "    try:\n",
    "        chunks = ungraph.ingest_document(\n",
    "            file_path,\n",
    "            pattern=SIMPLE_CHUNK_PATTERN,\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200,\n",
    "            clean_text=True\n",
    "        )\n",
    "        all_chunks_simple.extend(chunks)\n",
    "        print(f\"   ‚úÖ {len(chunks)} chunks creados\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Total chunks con patr√≥n SIMPLE_CHUNK: {len(all_chunks_simple)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explorar estructura del grafo SIMPLE_CHUNK\n",
    "driver = graph_session()\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        MATCH (n)\n",
    "        RETURN labels(n)[0] as label, count(n) as count\n",
    "        ORDER BY count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    print(\"üìä ESTRUCTURA DEL GRAFO (SIMPLE_CHUNK):\")\n",
    "    print(\"=\" * 80)\n",
    "    for record in result:\n",
    "        print(f\"   {record['label']}: {record['count']} nodos\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 6.1: Visualizar Grafo SIMPLE_CHUNK\n",
    "\n",
    "Visualizamos el grafo usando yFiles for Jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar funciones de visualizaci√≥n\n",
    "from src.notebooks.graph_visualization import visualize_simple_chunk_pattern\n",
    "from src.utils.graph_operations import graph_session\n",
    "\n",
    "print(\"üé® VISUALIZANDO PATR√ìN SIMPLE_CHUNK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "driver = graph_session()\n",
    "try:\n",
    "    visualize_simple_chunk_pattern(driver, limit=25)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Error al visualizar: {e}\")\n",
    "    print(\"üí° Aseg√∫rate de tener yfiles_jupyter_graphs_for_neo4j instalado\")\n",
    "    print(\"   Instalar con: pip install yfiles-jupyter-graphs-for-neo4j\")\n",
    "finally:\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 7: Resumen Comparativo\n",
    "\n",
    "Comparamos ambos patrones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä RESUMEN COMPARATIVO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "comparison = {\n",
    "    \"FILE_PAGE_CHUNK\": {\n",
    "        \"chunks\": len(all_chunks_default),\n",
    "        \"estructura\": \"File ‚Üí Page ‚Üí Chunk\",\n",
    "        \"relaciones\": \"CONTAINS, HAS_CHUNK, NEXT_CHUNK\",\n",
    "        \"uso\": \"Documentos con estructura jer√°rquica\"\n",
    "    },\n",
    "    \"SIMPLE_CHUNK\": {\n",
    "        \"chunks\": len(all_chunks_simple),\n",
    "        \"estructura\": \"Solo Chunk\",\n",
    "        \"relaciones\": \"Ninguna\",\n",
    "        \"uso\": \"Documentos simples sin jerarqu√≠a\"\n",
    "    }\n",
    "}\n",
    "\n",
    "for pattern_name, info in comparison.items():\n",
    "    print(f\"\\n{pattern_name}:\")\n",
    "    print(f\"   Chunks creados: {info['chunks']}\")\n",
    "    print(f\"   Estructura: {info['estructura']}\")\n",
    "    print(f\"   Relaciones: {info['relaciones']}\")\n",
    "    print(f\"   Uso recomendado: {info['uso']}\")\n",
    "\n",
    "print(\"\\n‚úÖ Notebook completado exitosamente\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
