# Ungraph ‚Äî Investigaci√≥n t√©cnico-cient√≠fica

**Resumen:**
Este documento (`article/ungraph.md`) ser√° el repositorio central del trabajo de investigaci√≥n t√©cnico-cient√≠fica que respalda la librer√≠a Ungraph. Su prop√≥sito es articular la motivaci√≥n, la metodolog√≠a experimental, los resultados y las referencias bibliogr√°ficas completas que justifican el dise√±o (ingesti√≥n, chunking, patrones GraphRAG, evaluaci√≥n y ontolog√≠as).

## Objetivo
Formalizar y documentar, con rigor cient√≠fico y reproducible, los experimentos y resultados que soportan las decisiones de dise√±o de Ungraph (estrategias de chunking, pipelines h√≠bridos de recuperaci√≥n, uso de Neo4j como almac√©n vectorial vs alternativas, y la ontolog√≠a propuesta para `File`/`Page`/`Chunk`).

## Alcance de la investigaci√≥n
- Evaluaciones emp√≠ricas de estrategias de chunking (fixed-size, lexical, semantic, hierarchical) por dominio (financiero, biomedicina, papers cient√≠ficos, negocio).  
- Comparaci√≥n de estrategias de recuperaci√≥n: vector-only, text-only, hybrid, hybrid + graph expansion + LM reranker.  
- Benchmarks de indexaci√≥n/vector search: Neo4j vector indexes vs FAISS/Milvus/Weaviate (latencia, recall, coste).  
- Formalizaci√≥n ontol√≥gica (`File`, `Page`, `Chunk`) y mapeos a vocabularios est√°ndar (schema.org, PROV-O).  
- Reproducibilidad: scripts, Opik experiment configs y OpenAI Evals para evaluaciones model-graded y human-in-the-loop.

## Metodolog√≠a (resumen)
1. Preparaci√≥n de datasets (EDGAR/financial filings, BioASQ/PubMedQA, arXiv subsets, internal SOPs).  
2. Implementaci√≥n de variantes (chunkers, retrievers, pattern execution).  
3. Ejecuci√≥n de experimentos E1‚ÄìE4 con harness Opik y registro de m√©tricas (recall@k, MRR, QA-F1, inference accuracy, hallucination rate, latency).  
4. An√°lisis estad√≠stico y reporte reproducible (notebooks, tablas y gr√°ficos).

### Metodolog√≠a experimental ‚Äî Protocolo reproducible üß™

**Objetivo:** Definir un protocolo replicable paso a paso para ejecutar y evaluar comparativas entre pipelines control (ET) y ETI y sus variantes (LM‚Äëonly, symbolic‚Äëonly, neuro‚Äësymbolic). Todas las ejecuciones deben grabar metadatos de entorno, seeds y bundles PROV para trazabilidad.

1) Entorno reproducible
- Usar entorno virtual (`python -m venv .venv` o Conda) y fijar Python (ej. 3.11). Ejecutar `pip freeze > requirements.txt` y capturar el hash de commit: `git rev-parse --short HEAD`.
- Registrar: SO, versiones de paquetes, URI de bases (Neo4j), OPIK env var present (no incluir llaves en artefactos), y `RANDOM_SEED` en env.

2) Adquisici√≥n y preparaci√≥n de datasets
- EDGAR/10‚ÄëK: script `scripts/fetch_edgar.py --out data/edgar/` (parseo, segmentaci√≥n por secciones).  
- BioASQ/PubMedQA: usar dumps oficiales o APIs; almacenar en `data/biomed/` con manifest JSON (sha256 checksums).  
- arXiv subsets: extraer por query (arXiv category) y guardar metadatos.  
- Generar tabla `experiments/datasets.csv` (placeholder) con columnas: dataset, URL, license, n_documents, n_chunks_estimated, notes.

3) Definir pipelines y variantes
- Pipelines: ET (Extract + Transform) y ETI (Extract + Transform + Inference).  
- Variantes de inferencia: `lm-only`, `symbolic-only`, `neuro-symbolic`.
- Implementar cada pipeline como un `dag` reproducible; los configs estar√°n en `experiments/<domain>/<pipeline>.yaml`.

4) Configuraci√≥n Opik (plantilla)
- Crear `experiments/finance/etik_finance_opik.yaml` con placeholders. No incluir OPIK_API_KEY en repositorio; usar variables de entorno.

Ejemplo (plantilla, no incluir secretos):

```yaml
experiment_name: finance_eti_v1
dataset: edgar
pipeline: ETI
inference: lm-only
opik:
  api_key: ${OPIK_API_KEY}
  model: openai-xyz
  timeout: 60
seeds:
  random_seed: 42
output:
  dir: experiments/finance_eti_v1/
```

5) Ejecuci√≥n (comandos reproducibles)
- Ejemplo: `python scripts/run_experiment.py --config experiments/finance/finance_eti_v1.yaml --seed 42 --out experiments/finance_eti_v1/`
- Cada ejecuci√≥n debe escribir un `metadata.json` con: seed, git_hash, timestamp, pipeline, config path, host, package versions.

6) Salida y artefactos
- Guardar: embeddings (binary/ndjson), `chunks.jsonl`, `inferred_facts.jsonl` (tripletas), `prov_bundle.json` (PROV), `evaluation/` con outputs y logs.
- Los hechos inferidos deben incluir campos: subject, predicate, object, confidence, provenance_ref.

7) M√©tricas y evaluaci√≥n autom√°tica
- Recuperaci√≥n: recall@k, MRR.  
- QA: F1 (micro/macro) sobre conjuntos anotados.  
- Inferencia: precision, recall, F1 sobre facts anotados (TP/FP/FN).  
- Hallucination rate: proportion of generated facts judged as ungrounded by annotators.  
- Coherencia de grafo: medidas de inconsistencia (contradicciones) y cobertura de ontolog√≠a.
- Definir scripts en `scripts/evaluate.py --pred inferred_facts.jsonl --gold gold_facts.jsonl --metrics all`.

8) Evaluaci√≥n humana (protocolo)
- Sampling: seleccionar N facts por pipeline (stratificado por confianza y dominio).  
- Instrucciones de anotadores: verificar si el hecho est√° expl√≠cito/entailed por la fuente y marcar fuente URL/loc.
- Medir inter-annotator agreement (Cohen's kappa) y adjudicar desacuerdos.

9) An√°lisis estad√≠stico
- Comparar pares (ET vs ETI) usando bootstrap resampling para intervalos de confianza y test de hip√≥tesis (paired t-test o Wilcoxon seg√∫n normalidad). Reportar p‚Äëvalues y tama√±o de efecto (Cohen's d).

10) Publicaci√≥n y reproducibilidad
- Publicar notebooks (convertir a HTML con `jupyter nbconvert --to html`) y subir a `docs/` y GitHub (tagged release). Registrar DOI en Zenodo para la release con los notebooks y datasets que puedan compartirse.
- Incluir `experiments/<id>/prov_bundle.json` para que terceros puedan auditar derivaciones.

> Nota: Las plantillas de configs y scripts estar√°n en `experiments/templates/` y se actualizar√°n con cada revisi√≥n; **no** se publicar√°n resultados hasta ejecutar los experimentos y validar las m√©tricas con los or√°culos y evaluaciones humanas.

  

## Entregables esperados
- Documento final con: motivaci√≥n, estado del arte, metodolog√≠a, resultados experimentales, discusi√≥n, limitaciones y recomendaciones.  
- Ficheros reproducibles (scripts, Opik configs, eval templates), notebooks y datasets anotados.  
- Ontolog√≠a publicada (`docs/ontology.md` + `ontology.owl` + JSON-LD examples).

## Relaci√≥n con las tareas del proyecto
Esta tarea final est√° registrada en el checklist maestro `_NET_STEPS.md` (ver `project/Instructions/_NET_STEPS.md`) como la tarea de documentaci√≥n t√©cnico-cient√≠fica que culmina el ciclo de investigaci√≥n y desarrollo. Debe incluir todas las referencias y evidencia recogida en la fase de evaluaci√≥n.

## Referencias (iniciales)
- Lewis et al. [1]
- Peng et al. [2]
- GraphRAG Patterns Catalog (Neo4j) [2]
- Miller 1956 [9]; Thalmann et al. 2019 [10] (chunking)
- Surveys de construcci√≥n de KG [4]

## Patr√≥n: Extracci√≥n ‚Äî Transformaci√≥n ‚Äî Inferencia (ETI)

**Descripci√≥n:**
El patr√≥n *Extracci√≥n ‚Äî Transformaci√≥n ‚Äî Inferencia* (ETI) se propone como la evoluci√≥n natural del cl√°sico ETL en el contexto de la ingenier√≠a del conocimiento y de las arquitecturas GraphRAG. ETI articula tres fases obligatorias en pipelines de conocimiento: 1) **Extracci√≥n** de fuentes crudas y metadatos; 2) **Transformaci√≥n** mediante chunking, normalizaci√≥n, enriquecimiento sem√°ntico y linking; 3) **Inferencia** donde modelos (LM/ML/razonadores simb√≥licos) generan hechos, relaciones, deducciones y explicaciones que alimentan los grafos y los √≠ndices vectoriales.

**Justificaci√≥n y posici√≥n en el art√≠culo:**
Esta hip√≥tesis es central para la investigaci√≥n: defendemos que a√±adir una fase expl√≠cita de inferencia (no meramente transductiva) distingue las soluciones de *knowledge engineering* modernas de los pipelines ETL tradicionales y mejora la calidad y utilidad de los artefactos (embeddings, nodos/aristas, tripletas). La hip√≥tesis **no debe eliminarse**: ser√° validada mediante experimentos y ablations en los que compararemos pipelines con y sin la fase de inferencia.

**Arquitectura propuesta y artefactos:**
- Extracci√≥n: parsers y connectors que producen `File`/`Page` y metadatos (timestamps, autor√≠a, contexto).  
- Transformaci√≥n: chunkers (fixed, lexical, hierarchical, semantic), normalizadores, detectores de idioma, y generadores de embeddings; salida: `Chunk` con anotaciones sem√°nticas.  
- Inferencia: modelos que extraen relaciones/facts, resuelven ambig√ºedad, hacen mapping a la ontolog√≠a (`File`/`Page`/`Chunk`), y generan aristas y propiedades para el grafo; salida: nodos, aristas, tripletas RDF/JSON-LD y se√±ales de confianza.

**Ejemplo (finanzas):**
1. Extracci√≥n: descarga y parseo de 10‚ÄëK/EDGAR.  
2. Transformaci√≥n: chunking por secciones y extracci√≥n de tablas, embeddings por chunk.  
3. Inferencia: LM que extrae hechos financieros (ingresos, activos) y relaciones (empresa‚Äësubsidiaria), normaliza entidades y crea/actualiza nodos y relaciones en el grafo.

**Medici√≥n y evaluaci√≥n experimental:**
Evaluaremos ETI mediante m√©tricas cl√°sicas y espec√≠ficas: recall@k y MRR en tareas de recuperaci√≥n, QA‚ÄëF1 en pipelines RAG, *inference accuracy* (precisi√≥n/recall sobre hechos extra√≠dos), tasa de *hallucination*, coherencia de grafo y coste/latencia. Proponemos estudios de ablation (sin inferencia vs con inferencia) para cuantificar su impacto en las tareas downstream.

**Relaci√≥n con otros componentes del estudio:**
ETI conecta directamente con: estrategias de chunking (fase Transformaci√≥n), patrones GraphRAG (uso de grafos y expansi√≥n), la ontolog√≠a `File`/`Page`/`Chunk` y las evaluaciones reproducibles (notebooks y Opik configs). Las decisiones implementadas en Ungraph (ingestores, chunkers, retrievers) est√°n dise√±adas para soportar y evaluar ETI.

## Filosof√≠a y justificaci√≥n epistemol√≥gica del ETI

**Resumen filos√≥fico:**
ETI toma como punto de partida cl√°sicas reflexiones sobre la transici√≥n *data ‚Üí information ‚Üí knowledge* (DIKW; Ackoff [7]; Rowley [6]; Zins [8]) y propone transformar los pipelines de preparaci√≥n de datos en procesos que expl√≠citamente construyen artefactos justificables y utilizables para razonamiento autom√°tico (con fiabilidad y trazabilidad). En t√©rminos epistemol√≥gicos, ETI busca convertir informaci√≥n estructurada (estructuras y anotaciones) en *creencias justificadas* (hechos, relaciones y reglas) que puedan sostener inferencias y decisiones automatizadas.

**Apoyos bibliogr√°ficos clave:**
- DIKW y los debates sobre la naturaleza de conocimiento (Ackoff; Rowley; Zins) muestran la necesidad de procesos que no s√≥lo estructuren datos sino que produzcan conocimiento justificable (ver discusi√≥n DIKW y cr√≠ticas). (v√©ase: DIKW reviews, 1989‚Äì2007).  
- Provenance y trazabilidad (W3C PROV) [3] son esenciales para que las inferencias sean evaluables, reproducibles y confiables; PROV formaliza c√≥mo representar entidades, actividades y agentes involucrados en la construcci√≥n de hechos (W3C PROV, 2013).
- Workflows de construcci√≥n de Knowledge Graphs muestran que la comunidad distingue etapas (IE ‚Üí KBC ‚Üí KG refinement) y discute la integraci√≥n de extracci√≥n y razonamiento [4].
- RAG [1] y GraphRAG [2] muestran que integrar memoria no‚Äëparam√©trica y grafos mejora el grounding factual y reduce la tasa de hallucination; ETI extiende estos enfoques al incorporar una fase expl√≠cita de inferencia que genera relaciones verificadas y trazables.
- Neuro‚Äësymbolic surveys [5] justifican el valor de combinar modelos estad√≠sticos (LMs) con razonamiento simb√≥lico para obtener explicabilidad y control sobre inferencias.

**Argumento metodol√≥gico y experimental (resumen):**
1. Hip√≥tesis: a√±adir una fase de inferencia que produzca hechos normalizados y con trazabilidad mejora la utilidad de los artefactos de conocimiento (mayor precision/recall en QA y recuperaci√≥n, menor tasa de hallucination y mayor coherencia de grafo).  
2. Protocolo: definir pipelines control (ET, no I) vs ETI y medir: inference accuracy (micro/macro), downstream QA‚ÄëF1, recall@k, MRR, hallucination rate, y m√©tricas de trazabilidad/provenance coverage (PROV con mediciones cuantificables).  
3. Ablations: tipos de inferencia (LM-only, symbolic-only, neuro-symbolic) y su impacto; evaluaci√≥n por dominio (finanzas, biomedicina, papers cient√≠ficos) y por nivel de confianza.

**Criterios de rigor cient√≠fico:**
- Usar datasets p√∫blicos y reproducibles, scripts y configs Opik, Evals autom√°ticos y evaluaciones humanas para facts cr√≠ticos; publicar notebooks y JSON-LD/PROV outputs para verificaci√≥n externa.  
- Auditar inferencias contra or√°culos o conjuntos anotados (fact‚Äëlevel labels) y reportar intervalos de confianza y an√°lisis de error (tipo de error: omisi√≥n vs comisi√≥n/hallucination).

**Impacto conceptual:**
ETI emerge como patr√≥n que combina principios de la ingenier√≠a del conocimiento, la Web sem√°ntica (ontolog√≠as y PROV), y pr√°cticas modernas de ML/LM (RAG/GraphRAG, neuro‚Äësymbolic), ofreciendo un marco coherente para construir *sistemas de conocimiento confiables y explicables*.

---

*Estado:* Esta p√°gina contiene ahora la descripci√≥n de alcance y la estructura que seguir√° el trabajo cient√≠fico; el borrador final se completar√° despu√©s de ejecutar los experimentos y consolidar resultados (ver `_NET_STEPS.md` para seguimiento).

## Estructura del art√≠culo y placeholders de resultados

Para que este documento mantenga un estilo y rigor acad√©mico (tipo paper cient√≠fico), se ha reescrito la organizaci√≥n como sigue. **Importante:** no se inventan resultados; todas las secciones marcadas como *Resultados* o *Hallazgos* contienen placeholders que ser√°n completados solamente tras la ejecuci√≥n de los experimentos reproducibles y la recolecci√≥n de m√©tricas.

1. Introducci√≥n y motivaci√≥n ‚Äî exposici√≥n del problema y la hip√≥tesis ETI (ya incluida).  
2. Estado del arte ‚Äî revisi√≥n de RAG/GraphRAG, DIKW, provenance y t√©cnicas de construcci√≥n de KGs (referencias a continuaci√≥n).  
3. Dise√±o del patr√≥n ETI ‚Äî definici√≥n formal, arquitectura, artefactos y casos de uso (secci√≥n ETI).  
4. Metodolog√≠a experimental ‚Äî datasets (EDGAR/10‚ÄëK, BioASQ/PubMedQA, arXiv subsets, SOPs), configuraciones (Opik), pipelines (ET, ETI, variantes neuro‚Äësimb√≥licas), m√©tricas y criterios de evaluaci√≥n.  
   - *Placeholders:* tablas con descripci√≥n de datasets y configuraciones de experimentos (TBD).  
5. Experimentos y resultados ‚Äî comparativas control/ETI y ablations (LM‚Äëonly, symbolic‚Äëonly, neuro‚Äësymbolic).  
   - *Resultados (placeholder):* (i) inference accuracy ‚Äî TBD; (ii) QA‚ÄëF1 y recall@k ‚Äî TBD; (iii) tasas de hallucination y coste/latencia ‚Äî TBD.  
6. Discusi√≥n y limitaciones ‚Äî an√°lisis cualitativo de errores, impacto de trazabilidad (PROV) y consideraciones √©ticas.  
7. Conclusiones y trabajos futuros ‚Äî validaci√≥n de la hip√≥tesis ETI y roadmap experimental.

> Nota: Todas las figuras, tablas y valores num√©ricos se incluir√°n solamente despu√©s de ejecutar los experimentos mencionados y compilar los notebooks/Opik configs reproducibles. No se a√±adir√° ninguna cifra hasta ese momento.

## Referencias

1. Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., & Riedel, S. (2020). Retrieval‚ÄëAugmented Generation for Knowledge‚ÄëIntensive NLP Tasks. arXiv:2005.11401. https://arxiv.org/abs/2005.11401

2. Peng, B., Zhu, Y., Liu, Y., Bo, X., Shi, H., Hong, C., & Tang, S. (2024). Graph Retrieval‚ÄëAugmented Generation: A Survey. arXiv:2408.08921. https://arxiv.org/abs/2408.08921

3. W3C Provenance Working Group. (2013). PROV‚ÄëOverview. W3C Note. https://www.w3.org/TR/prov-overview/

4. Zhong, L., Wu, J., Li, Q., & Peng, H. (2023). A Comprehensive Survey on Automatic Knowledge Graph Construction. arXiv:2302.05019. https://arxiv.org/abs/2302.05019

5. d'Avila Garcez, A., Gori, M., Lamb, L. C., Serafini, L., Spranger, M., & Tran, S. N. (2019). Neural‚ÄëSymbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning. arXiv:1905.06088. https://arxiv.org/abs/1905.06088

6. Rowley, J. (2007). The Wisdom Hierarchy: Representations of the DIKW Hierarchy. Journal of Information & Communication Science. https://doi.org/10.1177/0165551506070706

7. Ackoff, R. (1989). From Data to Wisdom. Journal of Applied Systems Analysis.

8. Zins, C. (2007). Conceptual Approaches for Defining Data, Information, and Knowledge. Journal of the American Society for Information Science and Technology, 58(4), 479‚Äì493. https://doi.org/10.1002/asi.20508

9. Miller, G. A. (1956). The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information. Psychological Review, 63(2), 81‚Äì97. https://doi.org/10.1037/h0043158

10. Thalmann, M., Souza, A. S., & Oberauer, K. (2019). How does chunking help working memory? Journal of Experimental Psychology. https://psycnet.apa.org/record/2018-18179-001

**BibTeX:** `article/references.bib` contiene las entradas BibTeX para las referencias listadas.

**Notas (enlaces directos):**
[1]: https://arxiv.org/abs/2005.11401
[2]: https://arxiv.org/abs/2408.08921
[3]: https://www.w3.org/TR/prov-overview/
[4]: https://arxiv.org/abs/2302.05019
[5]: https://arxiv.org/abs/1905.06088
[6]: https://doi.org/10.1177/0165551506070706
[7]: (Ackoff 1989)
[8]: https://doi.org/10.1002/asi.20508
[9]: https://doi.org/10.1037/h0043158
[10]: https://psycnet.apa.org/record/2018-18179-001

---

*Estado:* Se ha a√±adido la bibliograf√≠a en formato APA numerada y un listado de enlaces directos; la BibTeX fuente est√° disponible en `article/references.bib`. Los placeholders de resultados esperan la ejecuci√≥n de experimentos reproducibles antes de su completado.