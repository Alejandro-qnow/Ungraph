# Action Checklist: Mejoras al ArtÃ­culo Ungraph

**Basado en:** `article/technical_evaluation.md`  
**Fecha:** 25 de diciembre de 2025

---

## ğŸ”´ CRÃTICO - Hacer ANTES de Experimentos

### âœ… Tarea 1: Corregir Referencias BibliogrÃ¡ficas
**Tiempo estimado:** 1-2 horas  
**Archivos:** `article/ungraph.md`, `article/references.bib`

- [ ] **1.1** Corregir lÃ­nea 104: cambiar `[2]` duplicado
  - Actual: "GraphRAG Patterns Catalog (Neo4j) [2]"
  - Debe ser: "GraphRAG Patterns Catalog (Neo4j) [3]"
  
- [ ] **1.2** AÃ±adir nueva entrada en `references.bib`:
```bibtex
@misc{neo4j2024graphrag,
  title={GraphRAG Patterns Catalog},
  author={{Neo4j, Inc.}},
  year={2024},
  howpublished={\url{https://graphrag.com/reference/}},
  note={Accessed: 2025-12-25}
}
```

- [ ] **1.3** Renumerar referencias posteriores (W3C PROV serÃ¡ [4], Zhong serÃ¡ [5], etc.)

- [ ] **1.4** Completar DOIs faltantes en `references.bib`:
  - lewis2020rag: aÃ±adir DOI
  - peng2024graphrag: aÃ±adir DOI
  - zhong2023kg: aÃ±adir DOI
  - garcez2019neural: aÃ±adir DOI

- [ ] **1.5** Estandarizar formato:
  - Decidir: numÃ©rico [1], [2] O autor-aÃ±o (Ackoff 1989)
  - **RecomendaciÃ³n:** numÃ©rico para paper cientÃ­fico
  - Unificar lÃ­neas 137-142 con resto del documento

- [ ] **1.6** Verificar que todos los [N] en texto tienen entrada en referencias

**Test de validaciÃ³n:**
```bash
# Contar referencias en texto
grep -o '\[[0-9]\+\]' article/ungraph.md | sort -u

# Contar entradas en references.bib
grep -c '^@' article/references.bib

# Deben coincidir
```

---

### âœ… Tarea 2: Reescribir Abstract
**Tiempo estimado:** 30-45 minutos  
**Archivo:** `article/ungraph.md` (lÃ­neas 3-4)

- [ ] **2.1** Expandir abstract a 150-250 palabras

- [ ] **2.2** Seguir estructura IMRAD:
  - [ ] Contexto (1 frase): "Las arquitecturas RAG enfrentan desafÃ­os..."
  - [ ] Gap/Problema (1 frase): "Los pipelines ETL no capturan inferencia explÃ­cita..."
  - [ ] Propuesta (2 frases): "Proponemos el patrÃ³n ETI... Implementamos en Ungraph..."
  - [ ] MÃ©todo (1-2 frases): "Evaluamos mediante experimentos en 4 dominios..."
  - [ ] Resultados (2 frases): "[TBD - cuando estÃ©n disponibles]"
  - [ ] ConclusiÃ³n (1 frase): "ETI proporciona un marco coherente..."

- [ ] **2.3** VersiÃ³n borrador para review (puede incluir "resultados pendientes")

**Template sugerido:**
```markdown
**Abstract:**

Las arquitecturas modernas de Retrieval-Augmented Generation (RAG) enfrentan 
desafÃ­os en la construcciÃ³n de grafos de conocimiento confiables y trazables. 
Los pipelines tradicionales ETL (Extract-Transform-Load) no capturan explÃ­citamente 
la fase de inferencia necesaria para generar conocimiento justificable. Este trabajo 
propone el patrÃ³n Extract-Transform-Inference (ETI) como evoluciÃ³n del ETL, aÃ±adiendo 
una fase explÃ­cita de inferencia que genera hechos normalizados con trazabilidad 
PROV-O. Implementamos ETI en la librerÃ­a Ungraph, que construye Lexical Graphs 
sobre Neo4j integrando chunking estratÃ©gico, embeddings vectoriales y patrones 
GraphRAG. Evaluamos la efectividad de ETI mediante experimentos reproducibles en 
cuatro dominios (financiero, biomÃ©dico, cientÃ­fico y general), comparando pipelines 
control (ET) versus ETI en mÃ©tricas de recuperaciÃ³n (recall@k, MRR), calidad de QA 
(F1), precisiÃ³n de inferencia y tasa de hallucination. [Resultados pendientes de 
ejecuciÃ³n experimental]. Los experimentos incluyen ablation studies de tres tipos 
de inferencia (LM-only, symbolic-only, neuro-symbolic) para identificar la estrategia 
Ã³ptima por dominio. El patrÃ³n ETI demuestra [conclusiÃ³n pendiente tras experimentos] 
y proporciona un marco coherente para construir sistemas de conocimiento confiables, 
integrando principios de ingenierÃ­a del conocimiento, Web semÃ¡ntica (ontologÃ­as, PROV) 
y neuro-symbolic computing.
```

---

### âœ… Tarea 3: Formalizar PatrÃ³n ETI
**Tiempo estimado:** 2-3 horas  
**Archivo:** `article/ungraph.md` (nueva subsecciÃ³n en "PatrÃ³n ETI")

- [ ] **3.1** AÃ±adir "DefiniciÃ³n Formal" despuÃ©s de lÃ­nea 111:

```markdown
### DefiniciÃ³n Formal del PatrÃ³n ETI

**DefiniciÃ³n 1 (Pipeline ETI):**
Un pipeline ETI es una tupla P = (E, T, I, O, M) donde:

- **E (Extractors):** Conjunto de extractores {eâ‚, eâ‚‚, ..., eâ‚™} donde cada 
  eáµ¢: Sources â†’ Documents produce documentos estructurados con metadatos.
  
- **T (Transformers):** Conjunto de transformadores {tâ‚, tâ‚‚, ..., tâ‚˜} donde cada 
  tâ±¼: Documents â†’ Chunks produce chunks con embeddings y anotaciones semÃ¡nticas.
  
- **I (Inference):** Conjunto de modelos de inferencia {iâ‚, iâ‚‚, ..., iâ‚–} donde cada 
  iâ‚–: Chunks â†’ (Facts âˆª Relations âˆª Explanations) genera artefactos de conocimiento 
  con seÃ±ales de confianza y trazabilidad.
  
- **O (Ontology):** Esquema formal que define tipos de entidades, relaciones permitidas, 
  constraints y mapeos a vocabularios estÃ¡ndar (schema.org, PROV-O).
  
- **M (Metadata):** Estructura PROV-O que registra provenance de cada artefacto, 
  incluyendo: entidades derivadas, actividades ejecutadas, agentes responsables y 
  timestamps.

**Propiedades del Pipeline ETI:**
1. **Trazabilidad:** Todo fact f âˆˆ Facts tiene prov:wasDerivedFrom apuntando a su chunk fuente
2. **Validabilidad:** Todo fact f puede ser verificado contra source s mediante provenance chain
3. **Composabilidad:** Pipelines ETI pueden encadenarse (salida de Iâ‚– â†’ entrada de Eáµ¢â‚Šâ‚)
4. **Reproducibilidad:** Dado mismo input + config + seed â†’ mismo output
```

- [ ] **3.2** AÃ±adir tabla comparativa ETL vs ETI:

```markdown
### ComparaciÃ³n: ETL Tradicional vs ETI

| Aspecto | ETL Tradicional | ETI (Propuesto) |
|---------|----------------|-----------------|
| **Objetivo** | IntegraciÃ³n de datos | ConstrucciÃ³n de conocimiento |
| **Input** | Datos estructurados/semi-estructurados | Documentos no estructurados |
| **Output** | Tablas, esquemas relacionales | Grafos de conocimiento + facts |
| **Fases** | Extract â†’ Transform â†’ Load | Extract â†’ Transform â†’ **Inference** |
| **Inferencia** | ImplÃ­cita en Transform | **ExplÃ­cita y trazable** |
| **Trazabilidad** | Opcional (metadata) | Obligatoria (PROV-O) |
| **ValidaciÃ³n** | Schema validation | Fact validation + coherencia |
| **SemÃ¡ntica** | Schema-level | Ontology-level (OWL, RDF) |
| **Casos de uso** | Data warehousing, BI | RAG, QA, Knowledge Management |
| **Artefactos** | Filas en tablas | Nodos, aristas, tripletas RDF |
| **Explicabilidad** | Logs de transformaciÃ³n | Provenance chains completas |
```

- [ ] **3.3** Especificar criterios de "inferencia":

```markdown
### Â¿QuÃ© Constituye una "Inferencia"?

Una operaciÃ³n I es considerada "inferencia" (no mera transformaciÃ³n) si cumple:

1. **GeneraciÃ³n de conocimiento nuevo:** Produce facts/relations no explÃ­citos en input
2. **JustificaciÃ³n:** Puede explicar por quÃ© generÃ³ cada fact (reasoning chain)
3. **Confianza cuantificada:** Asigna score de confianza probabilÃ­stica a cada output
4. **Trazabilidad:** Registra provenance completa (quÃ© input, quÃ© modelo, quÃ© prompt)
5. **Validabilidad externa:** Output puede ser verificado contra ground truth o anotadores

**Ejemplos de inferencia:**
- âœ… LLM extrae "CompanyA posee 30% de CompanyB" de texto + normaliza entidades
- âœ… Razonador OWL deduce "PersonX es descendiente de PersonY" vÃ­a transitividad
- âœ… ML classifier predice "DocumentZ pertenece a CategoryK" con confidence=0.87

**No son inferencia (son transformaciÃ³n):**
- âŒ Chunking (divide texto pero no genera conocimiento nuevo)
- âŒ Embedding (representa texto pero no extrae facts)
- âŒ NormalizaciÃ³n de texto (limpia pero no interpreta)
```

---

### âœ… Tarea 4: Research Questions e HipÃ³tesis
**Tiempo estimado:** 1-2 horas  
**Archivo:** `article/ungraph.md` (nueva secciÃ³n antes de "MetodologÃ­a experimental")

- [ ] **4.1** AÃ±adir secciÃ³n "Research Questions":

```markdown
## Research Questions e HipÃ³tesis

### Research Questions

**RQ1: Efectividad de la Fase de Inferencia**
Â¿AÃ±adir una fase explÃ­cita de inferencia (I) mejora la calidad de recuperaciÃ³n y 
respuesta de preguntas comparado con pipelines que solo realizan extracciÃ³n y 
transformaciÃ³n (ET)?

**RQ2: Tipos de Inferencia por Dominio**
Â¿QuÃ© tipo de inferencia (LM-only, symbolic-only, neuro-symbolic) es mÃ¡s efectiva 
para diferentes dominios de conocimiento (financiero, biomÃ©dico, cientÃ­fico, general)?

**RQ3: Trade-off Trazabilidad vs Performance**
Â¿La trazabilidad completa con PROV-O mejora la confianza y explicabilidad del sistema 
sin sacrificar significativamente el rendimiento (latencia, throughput)?

**RQ4: ComparaciÃ³n de Backends Vectoriales**
Â¿CÃ³mo se comparan diferentes backends de vector search (Neo4j, FAISS, Milvus, Weaviate) 
en tÃ©rminos de recall@k, latencia y escalabilidad para Lexical Graphs?
```

- [ ] **4.2** Formalizar hipÃ³tesis estadÃ­sticas:

```markdown
### HipÃ³tesis EstadÃ­sticas

#### H1: ETI Mejora Recall (RQ1)
- **Hâ‚€:** Î¼(recall@10_ETI) â‰¤ Î¼(recall@10_ET)
- **Hâ‚:** Î¼(recall@10_ETI) > Î¼(recall@10_ET)
- **Test:** Paired t-test, one-tailed, Î± = 0.05
- **Efecto mÃ­nimo:** Cohen's d â‰¥ 0.3 (efecto pequeÃ±o-mediano)
- **Muestra:** N â‰¥ 30 queries por dominio

#### H2: ETI Reduce Hallucination (RQ1)
- **Hâ‚€:** Î¼(hallucination_rate_ETI) â‰¥ Î¼(hallucination_rate_ET)
- **Hâ‚:** Î¼(hallucination_rate_ETI) < Î¼(hallucination_rate_ET)
- **Test:** Paired t-test, one-tailed, Î± = 0.05
- **Muestra:** N = 100 facts evaluados por anotadores humanos

#### H3: Neuro-Symbolic Supera LM-only (RQ2)
- **Hâ‚€:** Î¼(F1_neuro-symbolic) â‰¤ Î¼(F1_LM-only)
- **Hâ‚:** Î¼(F1_neuro-symbolic) > Î¼(F1_LM-only)
- **Test:** Wilcoxon signed-rank (si no normalidad), Î± = 0.05
- **Muestra:** N â‰¥ 30 queries por dominio Ã— 4 dominios

#### H4: PROV No Degrada Latencia (RQ3)
- **Hâ‚€:** Î¼(latency_with_PROV) > Î¼(latency_without_PROV) + 50ms
- **Hâ‚:** Î¼(latency_with_PROV) â‰¤ Î¼(latency_without_PROV) + 50ms
- **Test:** Paired t-test, Î± = 0.05
- **Threshold:** 50ms considerado aceptable
```

- [ ] **4.3** Definir variables:

```markdown
### Variables del Experimento

#### Variables Independientes (Factores)
1. **Pipeline:** {ET, ETI}
2. **Inference Type:** {none, LM-only, symbolic-only, neuro-symbolic}
3. **Domain:** {finance, biomedical, scientific, general}
4. **Chunking Strategy:** {fixed-512, lexical, semantic, hierarchical}
5. **Backend:** {Neo4j, FAISS, Milvus, Weaviate}

#### Variables Dependientes (Outcomes)
1. **RecuperaciÃ³n:**
   - recall@k (k âˆˆ {1, 5, 10, 20})
   - MRR (Mean Reciprocal Rank)
   - NDCG@10
   
2. **QA:**
   - F1 score (micro, macro)
   - Exact Match (EM)
   
3. **Inferencia:**
   - Precision, Recall, F1 sobre facts extraÃ­dos
   - Inference Accuracy (% facts correctos)
   
4. **Confiabilidad:**
   - Hallucination Rate (% facts no fundamentados)
   - Provenance Coverage (% facts con PROV completo)
   
5. **Performance:**
   - Latencia de query (p50, p95, p99 en ms)
   - Throughput (queries/segundo)
   - Latencia de indexaciÃ³n (docs/segundo)

#### Variables de Control
- Embedding model: "sentence-transformers/all-MiniLM-L6-v2"
- LLM (si aplica): GPT-4 o Claude 3
- Neo4j version: 5.x
- Python version: 3.12
- Hardware: [especificar CPU, RAM, GPU]
- Random seed: 42
```

---

### âœ… Tarea 5: Crear Figuras y Tablas BÃ¡sicas
**Tiempo estimado:** 3-4 horas  
**Archivos:** `article/ungraph.md`, crear imÃ¡genes en `article/figures/`

- [ ] **5.1** Crear diagrama de arquitectura ETI (ASCII o imagen):

```
OpciÃ³n 1: ASCII art (para markdown)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ETI Pipeline Architecture              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                      â”‚
â”‚  1. EXTRACT          2. TRANSFORM       3. INFERENCEâ”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚ Parsers  â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚ Chunkers â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚   LLM    â”‚â”‚
â”‚  â”‚ Loaders  â”‚       â”‚ Embeddersâ”‚       â”‚ Symbolic â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  Neuro   â”‚â”‚
â”‚       â”‚                  â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚       â–¼                  â–¼                   â”‚       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â–¼       â”‚
â”‚  â”‚   File   â”‚       â”‚  Chunk   â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚   Page   â”‚       â”‚ +Embeddiâ”‚       â”‚  Facts   â”‚â”‚
â”‚  â”‚+Metadata â”‚       â”‚   ngs    â”‚       â”‚Relations â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚                                             â”‚        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚     Neo4j Graph Database       â”‚
                      â”‚  â€¢ Nodes (File/Page/Chunk)     â”‚
                      â”‚  â€¢ Relations (CONTAINS, HAS_CHUNK)â”‚
                      â”‚  â€¢ Vector Index (embeddings)   â”‚
                      â”‚  â€¢ PROV-O metadata             â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  GraphRAG Search Patterns   â”‚
                      â”‚  â€¢ Basic Retriever          â”‚
                      â”‚  â€¢ Parent-Child Retriever   â”‚
                      â”‚  â€¢ Hybrid Search            â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- [ ] **5.2** Crear tabla de datasets:

```markdown
### Tabla 1: Datasets para EvaluaciÃ³n

| Dataset | Dominio | # Docs | # Tokens | # Queries | Licencia | URL |
|---------|---------|--------|----------|-----------|----------|-----|
| EDGAR 10-K (subset) | Financiero | 100 | ~5M | 50 | Public Domain | [SEC EDGAR](https://www.sec.gov/edgar) |
| BioASQ Task 11b | Biomedicina | 200 | ~8M | 100 | Academic | [BioASQ](http://bioasq.org/) |
| arXiv CS.AI (2024) | CientÃ­fico | 150 | ~6M | 75 | CC BY 4.0 | [arXiv](https://arxiv.org/) |
| MS MARCO Passages | General | 500 | ~2M | 200 | MS Research License | [MS MARCO](https://microsoft.github.io/msmarco/) |

**Total:** 950 documentos, ~21M tokens, 425 queries
**Splits:** 70% train, 15% validation, 15% test (estratificado por dominio)
**Preprocesamiento:** Ver `scripts/prepare_datasets.py`
**Checksums:** Ver `experiments/datasets_manifest.json`
```

- [ ] **5.3** Crear tabla comparativa ETL vs ETI (ya incluida en Tarea 3.2)

- [ ] **5.4** Crear tabla de mÃ©tricas:

```markdown
### Tabla 2: MÃ©tricas de EvaluaciÃ³n

| CategorÃ­a | MÃ©trica | DefiniciÃ³n | Rango | Objetivo |
|-----------|---------|------------|-------|----------|
| **RecuperaciÃ³n** | recall@10 | ProporciÃ³n de docs relevantes en top-10 | [0,1] | Maximizar |
| | MRR | Media del reciproco del rank del 1er relevante | [0,1] | Maximizar |
| | NDCG@10 | Normalized Discounted Cumulative Gain | [0,1] | Maximizar |
| **QA** | F1-score | Media armÃ³nica de P y R sobre tokens | [0,1] | Maximizar |
| | Exact Match | % respuestas exactamente correctas | [0,1] | Maximizar |
| **Inferencia** | Inference Acc | % facts correctos sobre total generados | [0,1] | Maximizar |
| | Fact Precision | TP / (TP + FP) sobre facts | [0,1] | Maximizar |
| | Fact Recall | TP / (TP + FN) sobre facts | [0,1] | Maximizar |
| **Confiabilidad** | Hallucination Rate | % facts no fundamentados en sources | [0,1] | Minimizar |
| | Provenance Coverage | % facts con trazabilidad PROV completa | [0,1] | Maximizar |
| **Performance** | Query Latency (p95) | 95th percentile de tiempo de query | ms | Minimizar |
| | Throughput | Queries procesadas por segundo | qps | Maximizar |

**EvaluaciÃ³n Humana:**
- 2+ anotadores por fact (sampling estratificado)
- Cohen's Îº â‰¥ 0.7 requerido para confiabilidad
- Desacuerdos resueltos por adjudicaciÃ³n
```

---

## ğŸŸ¡ IMPORTANTE - Hacer ANTES de Publicar

### âœ… Tarea 6: Formalizar MÃ©tricas EspecÃ­ficas
**Tiempo estimado:** 2 horas  
**Archivo:** `article/ungraph.md` (ampliar secciÃ³n de mÃ©tricas)

- [ ] **6.1** DefiniciÃ³n formal de Hallucination Rate:

```markdown
**DefiniciÃ³n 2 (Hallucination Rate):**

Sea F = {fâ‚, fâ‚‚, ..., fâ‚™} el conjunto de facts generados por el sistema I.
Sea S = {sâ‚, sâ‚‚, ..., sâ‚˜} el conjunto de source documents.

Un fact fáµ¢ = (subject, predicate, object) es **hallucinated** si:
  âˆ„ sâ±¼ âˆˆ S tal que fáµ¢ estÃ¡ explÃ­citamente mencionado O 
  puede ser inferido deductivamente de sâ±¼ segÃºn anotadores humanos

**Hallucination Rate = |{fáµ¢ âˆˆ F : fáµ¢ es hallucinated}| / |F|**

**Protocolo de evaluaciÃ³n:**
1. Samplear N facts (estratificado por confidence score y dominio)
2. Presentar a K â‰¥ 2 anotadores: fact + source documents
3. Anotadores marcan: {grounded, inferred, hallucinated}
4. Calcular Cohen's Îº para inter-annotator agreement
5. Requerir Îº â‰¥ 0.7; si no, reentrenar anotadores
6. Resolver desacuerdos por adjudicaciÃ³n con 3er anotador
```

- [ ] **6.2** DefiniciÃ³n formal de Graph Coherence:

```markdown
**DefiniciÃ³n 3 (Graph Coherence):**

Sea G = (V, E) el knowledge graph generado por pipeline ETI.
Sea O = (C, R, A) la ontologÃ­a con:
- C: conjunto de clases (tipos de nodos)
- R: conjunto de relaciones permitidas
- A: conjunto de axiomas/constraints

**MÃ©tricas de coherencia:**

1. **Inconsistency Rate:**
   IR = |{a âˆˆ A : a es violado en G}| / |A|
   
   Ejemplos de violaciones:
   - Constraint de cardinalidad: "File tiene mÃ¡ximo 1 author" pero node File:123 tiene 3
   - Constraint de tipo: "HAS_CHUNK.target debe ser Chunk" pero apunta a File
   - Constraint lÃ³gico: "author â‰  reader" pero misma persona cumple ambos roles

2. **Ontology Coverage:**
   OC = |{c âˆˆ C : âˆƒv âˆˆ V con type(v) = c}| / |C|
   
   Mide quÃ© proporciÃ³n de clases de la ontologÃ­a estÃ¡n representadas en el grafo.

3. **Relation Completeness:**
   RC = |relaciones presentes| / |relaciones esperadas segÃºn O|
   
   Donde "esperadas" se define por reglas como:
   - "Si âˆƒ File entonces debe tener â‰¥1 Page"
   - "Si âˆƒ Chunk entonces debe tener embedding"

**Target:** IR < 0.05, OC > 0.80, RC > 0.90
```

### âœ… Tarea 7: Documentar OntologÃ­a Formalmente
**Tiempo estimado:** 3-4 horas  
**Archivos:** crear `docs/ontology.md` y `docs/ontology.owl`

- [ ] **7.1** Crear `docs/ontology.md`:

```markdown
# OntologÃ­a Ungraph: File-Page-Chunk

## Resumen
Esta ontologÃ­a define la estructura de conocimiento para Lexical Graphs en Ungraph.

## Clases

### File
**DescripciÃ³n:** Representa un documento completo ingestado al sistema.

**Propiedades:**
- `path`: String (URI del archivo original)
- `filename`: String
- `size`: Integer (bytes)
- `encoding`: String (e.g., "utf-8")
- `mime_type`: String (e.g., "text/markdown")
- `hash`: String (SHA256 del contenido)
- `created_at`: DateTime
- `ingested_at`: DateTime

**Relaciones salientes:**
- `CONTAINS â†’ Page` (cardinalidad: 1..*)

**Mapeo a vocabularios:**
- `owl:equivalentClass schema:DigitalDocument`

### Page
**DescripciÃ³n:** Unidad lÃ³gica dentro de un File (secciÃ³n, capÃ­tulo, pÃ¡gina fÃ­sica).

**Propiedades:**
- `page_number`: Integer
- `title`: String (opcional)
- `section`: String (opcional, e.g., "Introduction")
- `word_count`: Integer
- `language`: String (ISO 639-1, e.g., "en")

**Relaciones salientes:**
- `HAS_CHUNK â†’ Chunk` (cardinalidad: 1..*)

**Relaciones entrantes:**
- `File CONTAINS â†’ Page`

**Mapeo a vocabularios:**
- `rdfs:subClassOf schema:WebPage` (con adaptaciones)

### Chunk
**DescripciÃ³n:** Fragmento de texto indexable con embedding vectorial.

**Propiedades:**
- `content`: String (texto del chunk)
- `embedding`: Float[] (vector de dimensiÃ³n D)
- `position`: Integer (posiciÃ³n en Page)
- `chunk_size`: Integer (caracteres)
- `chunk_index`: Integer (Ã­ndice global)
- `metadata`: JSON (metadata adicional flexible)

**Relaciones salientes:**
- `NEXT_CHUNK â†’ Chunk` (cardinalidad: 0..1)
- `SIMILAR_TO â†’ Chunk` (opcional, con property `score: Float`)

**Relaciones entrantes:**
- `Page HAS_CHUNK â†’ Chunk`

**Constraints:**
- `embedding` debe tener dimensiÃ³n D constante (e.g., 384 para MiniLM)
- `position` debe ser Ãºnico dentro de la misma Page
- `NEXT_CHUNK` no debe formar ciclos

## Relaciones

### CONTAINS (File â†’ Page)
- **Dominio:** File
- **Rango:** Page
- **Cardinalidad:** 1..* (File debe contener al menos 1 Page)
- **Inversa:** IS_PART_OF

### HAS_CHUNK (Page â†’ Chunk)
- **Dominio:** Page
- **Rango:** Chunk
- **Cardinalidad:** 1..* (Page debe tener al menos 1 Chunk)
- **Inversa:** BELONGS_TO_PAGE

### NEXT_CHUNK (Chunk â†’ Chunk)
- **Dominio:** Chunk
- **Rango:** Chunk
- **Cardinalidad:** 0..1 (Ãºltimo chunk no tiene next)
- **Propiedades:** Transitiva, no reflexiva, no simÃ©trica
- **Uso:** Preserva secuencialidad para recuperar contexto

### SIMILAR_TO (Chunk â†’ Chunk)
- **Dominio:** Chunk
- **Rango:** Chunk
- **Cardinalidad:** 0..*
- **Propiedades de la relaciÃ³n:**
  - `score`: Float [0,1] (similitud coseno)
  - `computed_at`: DateTime
- **Nota:** SimÃ©trica (si A similar a B, entonces B similar a A con mismo score)

## Axiomas y Constraints

1. **Unicidad de File:**
   - No puede haber dos Files con mismo `hash`

2. **Orden de Chunks:**
   - `NEXT_CHUNK` define orden total dentro de cada Page
   - No ciclos: âˆ„ camino Câ‚ â†’* Câ‚ via NEXT_CHUNK

3. **Integridad referencial:**
   - Todo Chunk debe pertenecer a exactamente 1 Page
   - Todo Page debe pertenecer a exactamente 1 File

4. **ValidaciÃ³n de embeddings:**
   - `len(embedding)` debe ser constante para todos los Chunks del mismo sistema
   - `embedding` no puede tener valores NaN o Inf

## Trazabilidad (PROV-O)

Cada entidad generada registra provenance:

```json
{
  "@context": "http://www.w3.org/ns/prov#",
  "entity": "chunk:123-1-5",
  "prov:wasDerivedFrom": "page:123-1",
  "prov:wasGeneratedBy": {
    "@type": "prov:Activity",
    "prov:used": ["page:123-1", "config:chunking-lexical"],
    "prov:startedAtTime": "2025-01-01T10:00:00Z",
    "prov:endedAtTime": "2025-01-01T10:00:05Z",
    "prov:wasAssociatedWith": {
      "@type": "prov:Agent",
      "prov:actedOnBehalfOf": "user:alejandro"
    }
  }
}
```

## Ejemplos

Ver `docs/examples/` para:
- `example_file_page_chunk.json`: Instancia completa en JSON-LD
- `example_inference_facts.json`: Facts generados por fase I
- `example_prov_bundle.json`: PROV bundle completo
```

- [ ] **7.2** Crear `docs/ontology.owl` (esqueleto):

```xml
<?xml version="1.0"?>
<rdf:RDF xmlns="http://ungraph.io/ontology#"
     xml:base="http://ungraph.io/ontology"
     xmlns:owl="http://www.w3.org/2002/07/owl#"
     xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
     xmlns:xml="http://www.w3.org/XML/1998/namespace"
     xmlns:xsd="http://www.w3.org/2001/XMLSchema#"
     xmlns:rdfs="http://www.w3.org/2000/01/rdf-schema#"
     xmlns:prov="http://www.w3.org/ns/prov#"
     xmlns:schema="http://schema.org/">
    
    <owl:Ontology rdf:about="http://ungraph.io/ontology">
        <rdfs:label>Ungraph Lexical Graph Ontology</rdfs:label>
        <rdfs:comment>Ontology for File-Page-Chunk structure in Ungraph</rdfs:comment>
        <owl:versionInfo>0.1.0</owl:versionInfo>
    </owl:Ontology>
    
    <!-- Classes -->
    <owl:Class rdf:about="http://ungraph.io/ontology#File">
        <rdfs:label>File</rdfs:label>
        <owl:equivalentClass rdf:resource="http://schema.org/DigitalDocument"/>
    </owl:Class>
    
    <owl:Class rdf:about="http://ungraph.io/ontology#Page">
        <rdfs:label>Page</rdfs:label>
        <rdfs:subClassOf rdf:resource="http://schema.org/WebPage"/>
    </owl:Class>
    
    <owl:Class rdf:about="http://ungraph.io/ontology#Chunk">
        <rdfs:label>Chunk</rdfs:label>
        <rdfs:comment>Text fragment with vector embedding</rdfs:comment>
    </owl:Class>
    
    <!-- Object Properties (Relations) -->
    <owl:ObjectProperty rdf:about="http://ungraph.io/ontology#contains">
        <rdfs:domain rdf:resource="http://ungraph.io/ontology#File"/>
        <rdfs:range rdf:resource="http://ungraph.io/ontology#Page"/>
        <rdfs:label>contains</rdfs:label>
    </owl:ObjectProperty>
    
    <owl:ObjectProperty rdf:about="http://ungraph.io/ontology#hasChunk">
        <rdfs:domain rdf:resource="http://ungraph.io/ontology#Page"/>
        <rdfs:range rdf:resource="http://ungraph.io/ontology#Chunk"/>
        <rdfs:label>has chunk</rdfs:label>
    </owl:ObjectProperty>
    
    <owl:ObjectProperty rdf:about="http://ungraph.io/ontology#nextChunk">
        <rdfs:domain rdf:resource="http://ungraph.io/ontology#Chunk"/>
        <rdfs:range rdf:resource="http://ungraph.io/ontology#Chunk"/>
        <rdfs:label>next chunk</rdfs:label>
        <rdf:type rdf:resource="http://www.w3.org/2002/07/owl#TransitiveProperty"/>
    </owl:ObjectProperty>
    
    <!-- Data Properties -->
    <owl:DatatypeProperty rdf:about="http://ungraph.io/ontology#content">
        <rdfs:domain rdf:resource="http://ungraph.io/ontology#Chunk"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </owl:DatatypeProperty>
    
    <owl:DatatypeProperty rdf:about="http://ungraph.io/ontology#filename">
        <rdfs:domain rdf:resource="http://ungraph.io/ontology#File"/>
        <rdfs:range rdf:resource="http://www.w3.org/2001/XMLSchema#string"/>
    </owl:DatatypeProperty>
    
    <!-- More properties... -->
    
</rdf:RDF>
```

- [ ] **7.3** Crear ejemplo JSON-LD en `docs/examples/example_file_page_chunk.json`

### âœ… Tarea 8: Crear Tabla de Datasets
**Tiempo estimado:** 1 hora  
**Archivo:** crear `experiments/datasets.csv`

- [ ] **8.1** Crear CSV con estructura:

```csv
dataset,domain,n_documents,n_tokens_approx,n_queries,license,url,notes,sha256_manifest
edgar_10k_subset,financial,100,5000000,50,Public Domain,https://www.sec.gov/edgar,"Subset of 10-K filings from 2023",abc123...
bioasq_task11b,biomedical,200,8000000,100,Academic Use,http://bioasq.org/,"BioASQ Challenge Task 11b",def456...
arxiv_cs_ai_2024,scientific,150,6000000,75,CC BY 4.0,https://arxiv.org/,"arXiv papers from cs.AI category",ghi789...
msmarco_passages,general,500,2000000,200,MS Research License,https://microsoft.github.io/msmarco/,"MS MARCO passage ranking dataset",jkl012...
```

- [ ] **8.2** AÃ±adir referencia en `article/ungraph.md` lÃ­nea 34

- [ ] **8.3** Crear scripts de descarga/preparaciÃ³n:
  - `scripts/fetch_edgar.py`
  - `scripts/fetch_bioasq.py`
  - `scripts/fetch_arxiv.py`
  - `scripts/fetch_msmarco.py`

### âœ… Tarea 9: AÃ±adir SecciÃ³n "Related Work"
**Tiempo estimado:** 2-3 horas  
**Archivo:** `article/ungraph.md` (nueva secciÃ³n despuÃ©s de IntroducciÃ³n)

- [ ] **9.1** Estructura sugerida:

```markdown
## Estado del Arte y Trabajos Relacionados

### Retrieval-Augmented Generation (RAG)

**RAG clÃ¡sico (Lewis et al. 2020 [1]):**
Lewis et al. introdujeron RAG combinando retrieval denso (DPR) con generaciÃ³n (BART). 
Su pipeline sigue estructura Extract (DPR indexing) â†’ Load (retrieve) â†’ Generate (BART), 
sin fase explÃ­cita de inferencia. Limitaciones: no captura relaciones entre documentos, 
no valida consistencia de facts generados, no provee trazabilidad.

**Diferencia con ETI:** Ungraph aÃ±ade fase I que genera facts verificables con PROV-O 
antes de indexar, permitiendo validaciÃ³n de consistencia y explicabilidad.

### GraphRAG y Knowledge Graph Construction

**GraphRAG Survey (Peng et al. 2024 [2]):**
Peng et al. revisan mÃ©todos que integran KGs con RAG. Identifican tres paradigmas:
1. Graph-enhanced retrieval (usar grafo para expansiÃ³n)
2. Graph-enhanced generation (usar grafo como context)
3. Graph construction from text (IE + KG building)

ETI se posiciona en paradigma (3) pero con foco en **trazabilidad y validaciÃ³n**.

**KG Construction (Zhong et al. 2023 [4]):**
Zhong et al. survey mÃ©todos de construcciÃ³n automÃ¡tica de KG: IE â†’ KBC â†’ KG refinement. 
Estos trabajos tÃ­picamente carecen de:
- Trazabilidad explÃ­cita de cada fact a source document
- EvaluaciÃ³n de hallucination en extracciÃ³n con LLMs
- IntegraciÃ³n con vector search para RAG

**Diferencia con ETI:** Ungraph unifica construcciÃ³n de KG con indexaciÃ³n vectorial, 
asegurando que cada fact tiene provenance PROV-O y puede ser trazado a chunks especÃ­ficos.

### Neuro-Symbolic Computing

**Garcez et al. 2019 [5]:**
Proponen integrar redes neuronales con razonamiento simbÃ³lico para obtener:
- Explicabilidad (symbolic rules)
- GeneralizaciÃ³n (neural learning)
- GarantÃ­as formales (logic constraints)

**AplicaciÃ³n en ETI:** La fase de inferencia puede ser:
- LM-only (puramente neural)
- Symbolic-only (reglas OWL/SWRL)
- Neuro-symbolic (hybrid: LLM extrae, reasoner valida)

Nuestros experimentos evalÃºan cuÃ¡l es mÃ¡s efectivo por dominio.

### Provenance y Trazabilidad

**W3C PROV-O (2013 [3]):**
EstÃ¡ndar para representar provenance de datos. Define:
- Entities (what)
- Activities (how)
- Agents (who)

**Uso en ETI:** Cada Chunk, Fact y Relation registra:
```turtle
:chunk123 prov:wasDerivedFrom :page45 ;
          prov:wasGeneratedBy :chunkingActivity .
:chunkingActivity prov:used :lexicalChunker ;
                  prov:wasAssociatedWith :user_alejandro .
```

**LimitaciÃ³n en literatura:** La mayorÃ­a de sistemas RAG/GraphRAG no registran provenance 
de forma estÃ¡ndar, dificultando reproducibilidad y auditorÃ­a.

### ComparaciÃ³n Directa con ETL

| Aspecto | ETL Tradicional | GraphRAG Actual | ETI (Ungraph) |
|---------|----------------|-----------------|---------------|
| Inferencia explÃ­cita | âŒ | Parcial | âœ… |
| Trazabilidad PROV | âŒ | âŒ | âœ… |
| ValidaciÃ³n de facts | âŒ | âŒ | âœ… (opcional) |
| IntegraciÃ³n vector+graph | âŒ | âœ… | âœ… |
| Reproducibilidad | Parcial | Parcial | âœ… (seeds+PROV) |

### Posicionamiento de ETI

ETI no reemplaza GraphRAG ni KG construction methods, sino que proporciona un **framework 
metodolÃ³gico** que:
1. Formaliza la fase de inferencia como componente explÃ­cito
2. Requiere trazabilidad end-to-end con PROV-O
3. Integra evaluaciÃ³n de hallucination y coherencia de grafo
4. Soporta evaluaciÃ³n reproducible con experiment tracking (Opik)

**Contribuciones novedosas:**
- Primera formalizaciÃ³n del patrÃ³n ETI con definiciÃ³n matemÃ¡tica
- Protocolo de reproducibilidad con PROV-O + Opik + OpenAI Evals
- EvaluaciÃ³n de tipos de inferencia (LM vs symbolic vs neuro-symbolic) por dominio
- OntologÃ­a File/Page/Chunk con mapeo a vocabularios estÃ¡ndar
```

### âœ… Tarea 10: Definir Variables Experimentales
**Tiempo estimado:** 1 hora  
**Archivo:** Ya cubierto en Tarea 4.3

---

## ğŸŸ¢ DESEABLE - Para Pulido Final

### âœ… Tarea 11: AÃ±adir MÃ©tricas de Eficiencia
- [ ] Especificar latencia de indexaciÃ³n (docs/segundo)
- [ ] Especificar query latency (p50, p95, p99)
- [ ] Especificar throughput (qps)
- [ ] Memory footprint (RAM/VRAM)
- [ ] Storage overhead (embeddings + grafo vs texto plano)

### âœ… Tarea 12: Discutir Escalabilidad
- [ ] LÃ­mites de Neo4j vector index (testear hasta N millones de vectors)
- [ ] Estrategias de batch processing
- [ ] Caching de queries frecuentes
- [ ] ComparaciÃ³n con arquitecturas distribuidas

### âœ… Tarea 13: Crear Archivo OWL
- [ ] Ya cubierto en Tarea 7.2

### âœ… Tarea 14: Ejemplos JSON-LD
- [ ] Crear `docs/examples/example_file_page_chunk.json`
- [ ] Crear `docs/examples/example_inference_facts.json`
- [ ] Crear `docs/examples/example_prov_bundle.json`

### âœ… Tarea 15: ContainerizaciÃ³n Docker
- [ ] Crear `Dockerfile` para entorno reproducible
- [ ] Incluir Neo4j, Python, dependencies
- [ ] Documentar en secciÃ³n "Reproducibilidad"

### âœ… Tarea 16: Pre-registro Protocolo
- [ ] Crear cuenta en OSF.io
- [ ] Registrar protocolo experimental antes de ejecutar
- [ ] Obtener DOI de pre-registro
- [ ] AÃ±adir referencia en artÃ­culo

---

## ğŸ“Š Seguimiento de Progreso

### Tareas Completadas: 0/16

- [ ] Tarea 1: Corregir referencias â±ï¸ 1-2h
- [ ] Tarea 2: Reescribir abstract â±ï¸ 30-45min
- [ ] Tarea 3: Formalizar ETI â±ï¸ 2-3h
- [ ] Tarea 4: Research questions â±ï¸ 1-2h
- [ ] Tarea 5: Figuras y tablas â±ï¸ 3-4h
- [ ] Tarea 6: Formalizar mÃ©tricas â±ï¸ 2h
- [ ] Tarea 7: Documentar ontologÃ­a â±ï¸ 3-4h
- [ ] Tarea 8: Tabla de datasets â±ï¸ 1h
- [ ] Tarea 9: Related Work â±ï¸ 2-3h
- [ ] Tarea 10: Variables â±ï¸ (cubierto en Tarea 4)
- [ ] Tarea 11: MÃ©tricas eficiencia â±ï¸ 1h
- [ ] Tarea 12: Escalabilidad â±ï¸ 1h
- [ ] Tarea 13: OWL â±ï¸ (cubierto en Tarea 7)
- [ ] Tarea 14: JSON-LD examples â±ï¸ 1-2h
- [ ] Tarea 15: Docker â±ï¸ 2h
- [ ] Tarea 16: Pre-registro â±ï¸ 1h

**Tiempo total estimado:** ~25-35 horas

---

## ğŸ¯ PriorizaciÃ³n Sugerida

### Semana 1 (8-10 horas)
1. Tarea 1 (referencias) - 2h
2. Tarea 2 (abstract) - 1h
3. Tarea 3 (ETI) - 3h
4. Tarea 4 (RQs) - 2h

### Semana 2 (10-12 horas)
5. Tarea 5 (figuras) - 4h
6. Tarea 6 (mÃ©tricas) - 2h
7. Tarea 8 (datasets) - 1h
8. Tarea 9 (related work) - 3h

### Semana 3 (8-10 horas)
9. Tarea 7 (ontologÃ­a) - 4h
10. Tarea 11-12 (eficiencia, escalabilidad) - 2h
11. Tarea 14 (JSON-LD) - 2h

### Opcional (4-5 horas)
12. Tarea 15 (Docker) - 2h
13. Tarea 16 (OSF pre-registro) - 1h

---

**Documento mantenido en:** `article/ACTION_CHECKLIST.md`  
**Ãšltima actualizaciÃ³n:** 2025-12-25
